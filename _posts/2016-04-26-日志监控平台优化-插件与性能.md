

### 调节memlock 

```shell
chmod +w  /etc/security/limits.conf
vim /etc/security/limits.conf 
cluster soft memlock unlimited
cluster hard memlock unlimited 
``` 

-- - -- 

### 安装es的marvel插件 

es中 

```shell
bin/plugin install license
bin/plugin install marvel-agent
``` 

kibana中 

```shell
bin/kibana plugin --install elasticsearch/marvel/latest
``` 
重启两个应用,点击kibana标题栏的九宫格切换kibana与marvel. 

默认我们注册的插件为试用版,可以免费获取基本版license.看[这里](https://www.elastic.co/guide/en/marvel/current/license-management.html) 

从邮件中获取一个json文件,按网页命令执行遇到困难的话需要按如下fix一下,加上get的参数才能成功更新license. 

```shell
curl -XPUT -u admin 'http://c6:9200/_license?acknowledge=true' -d @/Users/Slahser/Downloads/sky-slahser.json
```
效果如图: 

![](http://7xqjx7.com1.z0.glb.clouddn.com/image/Screen%20Shot%202016-04-30%20at%2015.54.47.png?imageView2/2/h/600)

-- - -- 

### 重启bash 

这个功能我们使用Supervisor解决掉了. 

当flume挂掉会自动重启,顺带启动bash. 

-- - -- 

### 锁定内存 

vim /etc/profile 

```conf
export ES_HEAP_SIZE=28G
```

elasticsearch.yml 

```yml
bootstrap.mlockall: true
``` 

-- - -- 

### 关闭swap

```shell
sudo swapoff -a
```  

-- - -- 

### 内存大小的预留 

上回书说到c5上部署了不止一台es,还有logstash和kibana在运行,jvm内存不宜设置过大. 
暂且留存8G供二者使用. 

后续我们要按照架构图将logstash做成集群,将flume的collector主备都部署起来.  

-- - -- 

### 尝试去解决es的Supervisor问题

上回书说到"elasticsearch这种启动方式自带deamon进程的形式,最好利用`bin/elasticsearch -d` 启动" 

我们尝试着用这样的方式去解决一下  

```conf
environment=HOME="/home/cluster",USER="cluster"  ;进行用户目录的配置
user = cluster       ; 用哪个用户启动
``` 

目前还没有测试,给自己留个可以优化的点. 

-- - -- 

### flume agent主机host的添加 

Host Interceptor  

```properties
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = host
a1.sources.r1.interceptors.i1.useIP = true
a1.sources.r1.interceptors.i1.hostHeader = hostname
``` 

同理我们添加Static Interceptor可以用来指定exec source的来源 

```properties
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = static
a1.sources.r1.interceptors.i1.key = filename
a1.sources.r1.interceptors.i1.value = error.log
``` 

src中添加的header用处是在sink中作为%{***}变量使用,可以直接依照规则落到hdfs中 

所以上述方法依然不是我们想要的,我们可以暴力的利用shell这样 

```shell
tail -F tt.log | sed --unbuffered "s/^/host:$(hostname) /" 
tail -F tt.log | sed "s/^/[$(hostname)]-/"
``` 

如果用户不满意这样的方式我们再自行写几个interceptor进行操作. 

-- - -- 

### flume agent日志的过滤 

-- - -- 

### logstash日志的拆分 

-- - -- 

### 常用字段开启doc_value 

-- - -- 

### 取消不必要字段的索引与存储 

-- - -- 


ES索引性能
索引配置
#关闭副本

index.number_of_shards: 1
index.number_of_replicas: 0

#加大translog刷新频率

index.translog.flush_threshold_ops: 10000

#加大index刷新频率,不指定单位默认为ms,1s=1秒

index.refresh_interval: 10s

自定义templates 
按type自定义字段，不用存储的字段不用存储，不用索引的字段不要索引，常用聚合字段开启doc_values属性

"somesfield": {
    "type": "string",
    "index": "no",
    "store": false,
    "dynamic": "strict",
    "doc_values": true,
    "fielddata": {
        "format": "doc_values"
    }
}

上面这个字段将不会被存储，不会被索引，但是会以doc_values方式保存在磁盘上参加聚合运算。

也可以在模板中设置_ttl过期时间：

curl -XPUT http://localhost:9200/_template/logstash
{
  "template" : "logstash*",
        "order": 99,
        "mappings": {
            "3alogic": {
                "_ttl": {
                    "enabled": true,
                    "default": "30d"
                }
            }            
        }
}

上面3alogic类型的文档在30天后自动删除。

ES详细安装配置参见：http://blog.csdn.net/jiao_fuyou/article/details/46694125

logstash

增加filter worker数 
filter是很占用内存和CPU的，适当加大filter worker number

bin/logstash agent -w 6 -f /home/jfy/soft/logstash-1.4.2/lib/logstash/config/shipper.conf1.4.2/logs/logstash.log
为filter开启6个线程

output => elasticsearch 批量参数调整

flush_size 批量写入ES数量
idle_flush_time 批量写入ES频率 
详情参见：http://blog.csdn.net/jiao_fuyou/article/details/49589425