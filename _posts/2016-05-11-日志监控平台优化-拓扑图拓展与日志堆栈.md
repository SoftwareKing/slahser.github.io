> 上次的版本我们方案是单机安装agent,execCommand的方式进行读取日志,存在日志丢失的隐患.也没有涉及离线相关的内容. 

> 实际是留了口子进行拓展的,我们来一发新的设计与优化. 

![](http://7xqjx7.com1.z0.glb.clouddn.com/image/Screen%20Shot%202016-05-11%20at%2010.53.50.png?imageView2/2/h/400) 

下面是新增的点介绍:

## 日志堆栈 

上次的版本我们的agent来自flume而不是logstash,对多行日志的支持并不是很好,我们采用下面的方式进行修复.  

我们舍弃之前的执行命令行读取的方式,在agent所在机器启用avro RPC服务接收日志,同时将log直接输入我们重写的flume的LoadBalanceLog4jAppender,把日志丢失的隐患排除掉一点. 

系在flume 1.6.0源码,修改`org.apache.flume.clients.log4jappender.Log4jAppender` 

在`String msg = layout != null ? layout.format(event) : message.toString();` 的下一行中填入 

```java
if(layout.ignoresThrowable()) {
    String[] s = event.getThrowableStrRep();
    if (s != null) {
        int len = s.length;
            for(int i = 0; i < len; i++) {
            msg += s[i];
            msg += Layout.LINE_SEP;
            }
    }
}
``` 

LoadBalancingLog4jAppender是Log4jAppender的之类,调用了父类的append方法,不需要多余的改动 

因为堆栈数目会比之前的单行日志大很多,所以我们修改`org.apache.flume.serialization.LineDeserializer` 

将其中`MAXLINE_DFLT`值改为`8192` 

重新package打包 Flume NG Core与Flume NG Clients,替换集群内agent上的jar包. 

再将Flume NG Clients上传至nexus,在应用中进行引用,引用的部分使用私服nexus信息 

替换项目内log4j配置: 

```properties
log4j.appender.flume = org.apache.flume.clients.log4jappender.LoadBalancingLog4jAppender
log4j.appender.flume.Hosts = c1:4444 c2:4444 c3:4444
log4j.appender.flume.UnsafeMode = true
log4j.appender.flume.Selector = RANDOM
log4j.appender.flume.layout=org.apache.log4j.PatternLayout
log4j.appender.flume.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %p [%c:%L] - %m%n
``` 

相应的,我们部署在应用服务器上的agent全部下掉,配置新的agent集群上(当前先放置于消息集群上,突然申请这么多机器老板会爆炸的吧..) 

flume-kafka.properties 

```properties
ag1.sources=src1
ag1.sinks=sink1
ag1.channels=chn1

ag1.sources.src1.type = avro
# 这个地方一定要写自己的host,不要写localhost
ag1.sources.src1.bind = [c1/c2/c3]
ag1.sources.src1.port = 4444
ag1.sources.src1.channels = chn1

ag1.channels.chn1.type = memory
ag1.channels.chn1.capacity = 1000
ag1.channels.chn1.transactionCapacity = 1000

ag1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink
ag1.sinks.sink1.topic = tt_topic
ag1.sinks.sink1.brokerList = c1:9092,c2:9092,c3:9092
ag1.sinks.sink1.channel = chn1 
``` 

而后丰富集群上supervisor配置启动flume. 

done. 

## flume collector的增加 

后续可以增加主备collector的部分,把agent链路放长一点,主备切换保持可用性,FileChannel部分可以落在collector中. 

## flume channel的切换 

看了来自美团的channel优化,新开发了DualChannel设置阈值来使用内存还是memory,我们把这个作为可优化的点,因为目前业务量不是很大,我们agent集群这部分的运维也不是很困难.  

## 日志host来源的添加 

我们这次又把老问题引回来了,host在日志中没有体现,而消息中间件又不保存来源,我们后续会重写应用系统中的Logger来加入需要的列都加入日志中. 

## 离线部分 

我们将消息消费两次,离线处理后落入HDFS或者直接从消息中间件落入HDFS都是可行的.目前组内没有这部分的开发计划,先留着这部分. 








